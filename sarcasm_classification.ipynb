{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier, AutoSklearnClassifier\n",
    "from autosklearn.pipeline.classification import BasePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.jsonl') as f:\n",
    "    train_data = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "      <td>[A minor child deserves privacy and should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           response  \\\n",
       "0  SARCASM  @USER @USER @USER I don't get this .. obviousl...   \n",
       "1  SARCASM  @USER @USER trying to protest about . Talking ...   \n",
       "2  SARCASM  @USER @USER @USER He makes an insane about of ...   \n",
       "3  SARCASM  @USER @USER Meanwhile Trump won't even release...   \n",
       "4  SARCASM  @USER @USER Pretty Sure the Anti-Lincoln Crowd...   \n",
       "\n",
       "                                             context  \n",
       "0  [A minor child deserves privacy and should be ...  \n",
       "1  [@USER @USER Why is he a loser ? He's just a P...  \n",
       "2  [Donald J . Trump is guilty as charged . The e...  \n",
       "3  [Jamie Raskin tanked Doug Collins . Collins lo...  \n",
       "4  [Man ... y ’ all gone “ both sides ” the apoca...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.jsonl') as f:\n",
    "    test_data = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
       "      <td>[Well now that ’ s problematic AF &lt;URL&gt;, @USER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
       "      <td>[Last week the Fake News said that a section o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
       "      <td>[@USER Let ’ s Aplaud Brett When he deserves i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
       "      <td>[Women generally hate this president . What's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>@USER @USER @USER The irony being that he even...</td>\n",
       "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           response  \\\n",
       "0  twitter_1  @USER @USER @USER My 3 year old , that just fi...   \n",
       "1  twitter_2  @USER @USER How many verifiable lies has he to...   \n",
       "2  twitter_3  @USER @USER @USER Maybe Docs just a scrub of a...   \n",
       "3  twitter_4  @USER @USER is just a cover up for the real ha...   \n",
       "4  twitter_5  @USER @USER @USER The irony being that he even...   \n",
       "\n",
       "                                             context  \n",
       "0  [Well now that ’ s problematic AF <URL>, @USER...  \n",
       "1  [Last week the Fake News said that a section o...  \n",
       "2  [@USER Let ’ s Aplaud Brett When he deserves i...  \n",
       "3  [Women generally hate this president . What's ...  \n",
       "4  [Dear media Remoaners , you excitedly sharing ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SARCASM        2500\n",
       "NOT_SARCASM    2500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min messages: 2, max messages: 20\n"
     ]
    }
   ],
   "source": [
    "context_length = train_data['context'].apply(len)\n",
    "print('min messages: {}, max messages: {}'.format(\n",
    "    context_length.min(),\n",
    "    context_length.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_length.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['response'] + ' ' + train_data['context'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "           'fp': make_scorer(fp), 'fn': make_scorer(fn),\n",
    "          'precision': 'precision',\n",
    "          'recall': 'recall',\n",
    "          'f1': 'f1'}\n",
    "res = cross_validate(text_clf, X, y, cv=skf, n_jobs=5, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.36322999, 0.36468983, 0.36570287, 0.37889481, 0.36366105]),\n",
       " 'score_time': array([0.08974624, 0.08730531, 0.08717227, 0.08364105, 0.08646512]),\n",
       " 'test_tp': array([378, 387, 385, 386, 416]),\n",
       " 'test_tn': array([360, 381, 345, 348, 361]),\n",
       " 'test_fp': array([140, 119, 155, 152, 139]),\n",
       " 'test_fn': array([122, 113, 115, 114,  84]),\n",
       " 'test_precision': array([0.72972973, 0.76482213, 0.71296296, 0.71747212, 0.74954955]),\n",
       " 'test_recall': array([0.756, 0.774, 0.77 , 0.772, 0.832]),\n",
       " 'test_f1': array([0.74263261, 0.7693837 , 0.74038462, 0.74373796, 0.78862559])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Avg precision: 0.7349072991177403, recall 0.7807999999999999, F1 score 0.7569528952384379\n"
     ]
    }
   ],
   "source": [
    "print('Macro Avg precision: {}, recall {}, F1 score {}'.format(np.average(res['test_precision']), np.average(res['test_recall']), np.average(res['test_f1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = text_clf.fit(X, y)\n",
    "test_res = final_model.predict(test_data['response'] + ' ' + test_data['context'].str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['id'] = test_data['id']\n",
    "result_df['result'] = pd.Series(le.inverse_transform(test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       result\n",
       "0  twitter_1  NOT_SARCASM\n",
       "1  twitter_2      SARCASM\n",
       "2  twitter_3  NOT_SARCASM\n",
       "3  twitter_4  NOT_SARCASM\n",
       "4  twitter_5      SARCASM"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer.txt', 'w') as f:\n",
    "    result_df.to_csv(f, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SARCASM        904\n",
       "NOT_SARCASM    896\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "text_clf2 = Pipeline([\n",
    "    ('vect', CountVectorizer(strip_accents = 'unicode',\n",
    "                       stop_words = 'english',\n",
    "                       lowercase = True)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', GradientBoostingClassifier()),\n",
    "])\n",
    "res2 = cross_validate(text_clf2, X, y, cv=skf, n_jobs=5, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.8076632 , 4.79586315, 4.77715111, 4.84718108, 4.78924918]),\n",
       " 'score_time': array([0.12416482, 0.12808394, 0.12694287, 0.12094998, 0.12623501]),\n",
       " 'test_tp': array([378, 384, 388, 400, 392]),\n",
       " 'test_tn': array([283, 301, 299, 295, 319]),\n",
       " 'test_fp': array([217, 199, 201, 205, 181]),\n",
       " 'test_fn': array([122, 116, 112, 100, 108]),\n",
       " 'test_precision': array([0.63529412, 0.65866209, 0.65874363, 0.66115702, 0.68411867]),\n",
       " 'test_recall': array([0.756, 0.768, 0.776, 0.8  , 0.784]),\n",
       " 'test_f1': array([0.69041096, 0.70914127, 0.71258035, 0.7239819 , 0.7306617 ])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Avg precision: 0.6595951083978028, recall 0.7767999999999999, F1 score 0.7133552357435496\n"
     ]
    }
   ],
   "source": [
    "print('Macro Avg precision: {}, recall {}, F1 score {}'.format(np.average(res2['test_precision']), np.average(res2['test_recall']), np.average(res2['test_f1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Avg precision: 0.6595951083978028, recall 0.7767999999999999, F1 score 0.7133552357435496\n"
     ]
    }
   ],
   "source": [
    "print('Macro Avg precision: {}, recall {}, F1 score {}'.format(np.average(res2['test_precision']), np.average(res2['test_recall']), np.average(res2['test_f1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "text_clf2 = Pipeline([\n",
    "    ('vect', CountVectorizer(strip_accents = 'unicode',\n",
    "                       stop_words = 'english',\n",
    "                       lowercase = True)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', GradientBoostingClassifier()),\n",
    "])\n",
    "res2 = cross_validate(text_clf2, X, y, cv=skf, n_jobs=5, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.97709894, 4.9373889 , 4.94328904, 4.9892199 , 4.9449892 ]),\n",
       " 'score_time': array([0.13985205, 0.14647508, 0.14524007, 0.14320922, 0.14607167]),\n",
       " 'test_tp': array([377, 378, 382, 400, 399]),\n",
       " 'test_tn': array([278, 302, 293, 295, 311]),\n",
       " 'test_fp': array([222, 198, 207, 205, 189]),\n",
       " 'test_fn': array([123, 122, 118, 100, 101]),\n",
       " 'test_precision': array([0.6293823 , 0.65625   , 0.64855688, 0.66115702, 0.67857143]),\n",
       " 'test_recall': array([0.754, 0.756, 0.764, 0.8  , 0.798]),\n",
       " 'test_f1': array([0.68607825, 0.70260223, 0.70156107, 0.7239819 , 0.73345588])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Avg precision: 0.6547835266531342, recall 0.7744, F1 score 0.7095358662886728\n"
     ]
    }
   ],
   "source": [
    "print('Macro Avg precision: {}, recall {}, F1 score {}'.format(np.average(res2['test_precision']), np.average(res2['test_recall']), np.average(res2['test_f1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astrok/opt/anaconda3/envs/py37/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 54305 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2020-11-29 16:39:41,852:AutoML(1):b3e75eddc9e5d37a77c4c778416dd791] Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (3599.634847)\n",
      "[WARNING] [2020-11-29 16:39:41,854:AutoML(1):b3e75eddc9e5d37a77c4c778416dd791] Capping the per_run_time_limit to 1799.0 to have time for a least 2 models in each process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astrok/opt/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents='unicode',\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, voca...\n",
       "                                       metadata_directory=None, metric=None,\n",
       "                                       n_jobs=-1,\n",
       "                                       output_folder='/Users/astrok/tmp/autosklearn_classification/sarcasm/out/',\n",
       "                                       per_run_time_limit=5760,\n",
       "                                       resampling_strategy='holdout',\n",
       "                                       resampling_strategy_arguments=None,\n",
       "                                       seed=1, smac_scenario_args=None,\n",
       "                                       time_left_for_this_task=3600,\n",
       "                                       tmp_folder='/Users/astrok/tmp/autosklearn_classification/sarcasm/tmp/'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = Pipeline([\n",
    "    ('vect', CountVectorizer(strip_accents = 'unicode',\n",
    "                       stop_words = 'english',\n",
    "                       lowercase = True)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AutoSklearnClassifier(\n",
    "        time_left_for_this_task=3600,\n",
    "        memory_limit=24576,\n",
    "        tmp_folder='/Users/astrok/tmp/autosklearn_classification/sarcasm/tmp/',\n",
    "        output_folder='/Users/astrok/tmp/autosklearn_classification/sarcasm/out/',\n",
    "        include_preprocessors=[\"no_preprocessing\", ],\n",
    "        resampling_strategy='cv',\n",
    "        resampling_strategy_arguments={'folds': 5},\n",
    "        n_jobs=-1,\n",
    "    )),\n",
    "])\n",
    "automl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(automl.steps[2][1].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_scores</th>\n",
       "      <th>status</th>\n",
       "      <th>budgets</th>\n",
       "      <th>param_balancing:strategy</th>\n",
       "      <th>param_classifier:__choice__</th>\n",
       "      <th>param_data_preprocessing:categorical_transformer:categorical_encoding:__choice__</th>\n",
       "      <th>param_data_preprocessing:categorical_transformer:category_coalescence:__choice__</th>\n",
       "      <th>...</th>\n",
       "      <th>param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles</th>\n",
       "      <th>param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution</th>\n",
       "      <th>param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max</th>\n",
       "      <th>param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min</th>\n",
       "      <th>param_classifier:libsvm_svc:coef0</th>\n",
       "      <th>param_classifier:libsvm_svc:degree</th>\n",
       "      <th>param_classifier:sgd:epsilon</th>\n",
       "      <th>param_classifier:sgd:eta0</th>\n",
       "      <th>param_classifier:sgd:l1_ratio</th>\n",
       "      <th>param_classifier:sgd:power_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.776970</td>\n",
       "      <td>24.727731</td>\n",
       "      <td>{'balancing:strategy': 'none', 'classifier:__c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Success</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718487</td>\n",
       "      <td>0.290044</td>\n",
       "      <td>0.036325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>20.545186</td>\n",
       "      <td>{'balancing:strategy': 'none', 'classifier:__c...</td>\n",
       "      <td>2</td>\n",
       "      <td>Success</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.957425</td>\n",
       "      <td>0.145949</td>\n",
       "      <td>0.046125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>21.247054</td>\n",
       "      <td>{'balancing:strategy': 'none', 'classifier:__c...</td>\n",
       "      <td>2</td>\n",
       "      <td>Success</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>25.223575</td>\n",
       "      <td>{'balancing:strategy': 'none', 'classifier:__c...</td>\n",
       "      <td>2</td>\n",
       "      <td>Success</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736314</td>\n",
       "      <td>0.264820</td>\n",
       "      <td>0.038469</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>18.340470</td>\n",
       "      <td>{'balancing:strategy': 'weighting', 'classifie...</td>\n",
       "      <td>2</td>\n",
       "      <td>Success</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weighting</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727951</td>\n",
       "      <td>0.265031</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>424.021845</td>\n",
       "      <td>{'balancing:strategy': 'weighting', 'classifie...</td>\n",
       "      <td>548</td>\n",
       "      <td>Timeout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weighting</td>\n",
       "      <td>extra_trees</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>...</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.017314</td>\n",
       "      <td>{'balancing:strategy': 'none', 'classifier:__c...</td>\n",
       "      <td>548</td>\n",
       "      <td>Timeout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001478</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.013409</td>\n",
       "      <td>{'balancing:strategy': 'none', 'classifier:__c...</td>\n",
       "      <td>548</td>\n",
       "      <td>Timeout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716937</td>\n",
       "      <td>0.293125</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.028406</td>\n",
       "      <td>{'balancing:strategy': 'weighting', 'classifie...</td>\n",
       "      <td>548</td>\n",
       "      <td>Timeout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weighting</td>\n",
       "      <td>sgd</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.904689</td>\n",
       "      <td>0.183092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'balancing:strategy': 'weighting', 'classifie...</td>\n",
       "      <td>548</td>\n",
       "      <td>Crash</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weighting</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.849249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score  mean_fit_time  \\\n",
       "497         0.776970      24.727731   \n",
       "453         0.776364      20.545186   \n",
       "248         0.776364      21.247054   \n",
       "375         0.776364      25.223575   \n",
       "407         0.776364      18.340470   \n",
       "..               ...            ...   \n",
       "490         0.000000     424.021845   \n",
       "553         0.000000      22.017314   \n",
       "554         0.000000      13.013409   \n",
       "555         0.000000      12.028406   \n",
       "556         0.000000       0.000000   \n",
       "\n",
       "                                                params  rank_test_scores  \\\n",
       "497  {'balancing:strategy': 'none', 'classifier:__c...                 1   \n",
       "453  {'balancing:strategy': 'none', 'classifier:__c...                 2   \n",
       "248  {'balancing:strategy': 'none', 'classifier:__c...                 2   \n",
       "375  {'balancing:strategy': 'none', 'classifier:__c...                 2   \n",
       "407  {'balancing:strategy': 'weighting', 'classifie...                 2   \n",
       "..                                                 ...               ...   \n",
       "490  {'balancing:strategy': 'weighting', 'classifie...               548   \n",
       "553  {'balancing:strategy': 'none', 'classifier:__c...               548   \n",
       "554  {'balancing:strategy': 'none', 'classifier:__c...               548   \n",
       "555  {'balancing:strategy': 'weighting', 'classifie...               548   \n",
       "556  {'balancing:strategy': 'weighting', 'classifie...               548   \n",
       "\n",
       "      status  budgets param_balancing:strategy param_classifier:__choice__  \\\n",
       "497  Success      0.0                     none                  libsvm_svc   \n",
       "453  Success      0.0                     none                  libsvm_svc   \n",
       "248  Success      0.0                     none                  libsvm_svc   \n",
       "375  Success      0.0                     none                  libsvm_svc   \n",
       "407  Success      0.0                weighting                  libsvm_svc   \n",
       "..       ...      ...                      ...                         ...   \n",
       "490  Timeout      0.0                weighting                 extra_trees   \n",
       "553  Timeout      0.0                     none                  libsvm_svc   \n",
       "554  Timeout      0.0                     none                  libsvm_svc   \n",
       "555  Timeout      0.0                weighting                         sgd   \n",
       "556    Crash      0.0                weighting                  libsvm_svc   \n",
       "\n",
       "    param_data_preprocessing:categorical_transformer:categorical_encoding:__choice__  \\\n",
       "497                                   one_hot_encoding                                 \n",
       "453                                        no_encoding                                 \n",
       "248                                        no_encoding                                 \n",
       "375                                        no_encoding                                 \n",
       "407                                        no_encoding                                 \n",
       "..                                                 ...                                 \n",
       "490                                   one_hot_encoding                                 \n",
       "553                                        no_encoding                                 \n",
       "554                                   one_hot_encoding                                 \n",
       "555                                   one_hot_encoding                                 \n",
       "556                                        no_encoding                                 \n",
       "\n",
       "    param_data_preprocessing:categorical_transformer:category_coalescence:__choice__  \\\n",
       "497                                 minority_coalescer                                 \n",
       "453                                 minority_coalescer                                 \n",
       "248                                     no_coalescense                                 \n",
       "375                                     no_coalescense                                 \n",
       "407                                 minority_coalescer                                 \n",
       "..                                                 ...                                 \n",
       "490                                 minority_coalescer                                 \n",
       "553                                     no_coalescense                                 \n",
       "554                                 minority_coalescer                                 \n",
       "555                                 minority_coalescer                                 \n",
       "556                                     no_coalescense                                 \n",
       "\n",
       "     ...  \\\n",
       "497  ...   \n",
       "453  ...   \n",
       "248  ...   \n",
       "375  ...   \n",
       "407  ...   \n",
       "..   ...   \n",
       "490  ...   \n",
       "553  ...   \n",
       "554  ...   \n",
       "555  ...   \n",
       "556  ...   \n",
       "\n",
       "    param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles  \\\n",
       "497                                                NaN                                          \n",
       "453                                                NaN                                          \n",
       "248                                                NaN                                          \n",
       "375                                                NaN                                          \n",
       "407                                                NaN                                          \n",
       "..                                                 ...                                          \n",
       "490                                             1550.0                                          \n",
       "553                                                NaN                                          \n",
       "554                                                NaN                                          \n",
       "555                                                NaN                                          \n",
       "556                                                NaN                                          \n",
       "\n",
       "    param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution  \\\n",
       "497                                                NaN                                                  \n",
       "453                                                NaN                                                  \n",
       "248                                                NaN                                                  \n",
       "375                                                NaN                                                  \n",
       "407                                                NaN                                                  \n",
       "..                                                 ...                                                  \n",
       "490                                            uniform                                                  \n",
       "553                                                NaN                                                  \n",
       "554                                                NaN                                                  \n",
       "555                                                NaN                                                  \n",
       "556                                                NaN                                                  \n",
       "\n",
       "    param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max  \\\n",
       "497                                           0.718487                             \n",
       "453                                           0.957425                             \n",
       "248                                                NaN                             \n",
       "375                                           0.736314                             \n",
       "407                                           0.727951                             \n",
       "..                                                 ...                             \n",
       "490                                                NaN                             \n",
       "553                                                NaN                             \n",
       "554                                           0.716937                             \n",
       "555                                           0.904689                             \n",
       "556                                                NaN                             \n",
       "\n",
       "    param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min  \\\n",
       "497                                           0.290044                             \n",
       "453                                           0.145949                             \n",
       "248                                                NaN                             \n",
       "375                                           0.264820                             \n",
       "407                                           0.265031                             \n",
       "..                                                 ...                             \n",
       "490                                                NaN                             \n",
       "553                                                NaN                             \n",
       "554                                           0.293125                             \n",
       "555                                           0.183092                             \n",
       "556                                                NaN                             \n",
       "\n",
       "     param_classifier:libsvm_svc:coef0  param_classifier:libsvm_svc:degree  \\\n",
       "497                           0.036325                                 2.0   \n",
       "453                           0.046125                                 2.0   \n",
       "248                           0.031333                                 2.0   \n",
       "375                           0.038469                                 2.0   \n",
       "407                           0.038771                                 2.0   \n",
       "..                                 ...                                 ...   \n",
       "490                                NaN                                 NaN   \n",
       "553                          -0.001478                                 3.0   \n",
       "554                           0.065918                                 2.0   \n",
       "555                                NaN                                 NaN   \n",
       "556                          -0.849249                                 NaN   \n",
       "\n",
       "     param_classifier:sgd:epsilon  param_classifier:sgd:eta0  \\\n",
       "497                           NaN                        NaN   \n",
       "453                           NaN                        NaN   \n",
       "248                           NaN                        NaN   \n",
       "375                           NaN                        NaN   \n",
       "407                           NaN                        NaN   \n",
       "..                            ...                        ...   \n",
       "490                           NaN                        NaN   \n",
       "553                           NaN                        NaN   \n",
       "554                           NaN                        NaN   \n",
       "555                           NaN                        NaN   \n",
       "556                           NaN                        NaN   \n",
       "\n",
       "    param_classifier:sgd:l1_ratio param_classifier:sgd:power_t  \n",
       "497                           NaN                          NaN  \n",
       "453                           NaN                          NaN  \n",
       "248                           NaN                          NaN  \n",
       "375                           NaN                          NaN  \n",
       "407                           NaN                          NaN  \n",
       "..                            ...                          ...  \n",
       "490                           NaN                          NaN  \n",
       "553                           NaN                          NaN  \n",
       "554                           NaN                          NaN  \n",
       "555                      0.000965                          NaN  \n",
       "556                           NaN                          NaN  \n",
       "\n",
       "[557 rows x 85 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_norm = pd.json_normalize(cv_res['params'], max_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balancing:strategy</th>\n",
       "      <th>classifier:__choice__</th>\n",
       "      <th>data_preprocessing:categorical_transformer:categorical_encoding:__choice__</th>\n",
       "      <th>data_preprocessing:categorical_transformer:category_coalescence:__choice__</th>\n",
       "      <th>data_preprocessing:numerical_transformer:imputation:strategy</th>\n",
       "      <th>data_preprocessing:numerical_transformer:rescaling:__choice__</th>\n",
       "      <th>feature_preprocessor:__choice__</th>\n",
       "      <th>classifier:random_forest:bootstrap</th>\n",
       "      <th>classifier:random_forest:criterion</th>\n",
       "      <th>classifier:random_forest:max_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>classifier:sgd:average</th>\n",
       "      <th>classifier:sgd:fit_intercept</th>\n",
       "      <th>classifier:sgd:learning_rate</th>\n",
       "      <th>classifier:sgd:loss</th>\n",
       "      <th>classifier:sgd:penalty</th>\n",
       "      <th>classifier:sgd:tol</th>\n",
       "      <th>classifier:sgd:epsilon</th>\n",
       "      <th>classifier:sgd:l1_ratio</th>\n",
       "      <th>classifier:sgd:eta0</th>\n",
       "      <th>classifier:sgd:power_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>mean</td>\n",
       "      <td>standardize</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighting</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>mean</td>\n",
       "      <td>standardize</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>standardize</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighting</td>\n",
       "      <td>extra_trees</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>median</td>\n",
       "      <td>standardize</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  balancing:strategy classifier:__choice__  \\\n",
       "0               none         random_forest   \n",
       "1          weighting         random_forest   \n",
       "2               none         random_forest   \n",
       "3               none         random_forest   \n",
       "4          weighting           extra_trees   \n",
       "\n",
       "  data_preprocessing:categorical_transformer:categorical_encoding:__choice__  \\\n",
       "0                                   one_hot_encoding                           \n",
       "1                                   one_hot_encoding                           \n",
       "2                                   one_hot_encoding                           \n",
       "3                                   one_hot_encoding                           \n",
       "4                                   one_hot_encoding                           \n",
       "\n",
       "  data_preprocessing:categorical_transformer:category_coalescence:__choice__  \\\n",
       "0                                 minority_coalescer                           \n",
       "1                                     no_coalescense                           \n",
       "2                                 minority_coalescer                           \n",
       "3                                     no_coalescense                           \n",
       "4                                 minority_coalescer                           \n",
       "\n",
       "  data_preprocessing:numerical_transformer:imputation:strategy  \\\n",
       "0                                               mean             \n",
       "1                                      most_frequent             \n",
       "2                                               mean             \n",
       "3                                      most_frequent             \n",
       "4                                             median             \n",
       "\n",
       "  data_preprocessing:numerical_transformer:rescaling:__choice__  \\\n",
       "0                                        standardize              \n",
       "1                               quantile_transformer              \n",
       "2                                        standardize              \n",
       "3                                        standardize              \n",
       "4                                        standardize              \n",
       "\n",
       "  feature_preprocessor:__choice__ classifier:random_forest:bootstrap  \\\n",
       "0                no_preprocessing                               True   \n",
       "1                no_preprocessing                              False   \n",
       "2                no_preprocessing                              False   \n",
       "3                no_preprocessing                              False   \n",
       "4                no_preprocessing                                NaN   \n",
       "\n",
       "  classifier:random_forest:criterion classifier:random_forest:max_depth  ...  \\\n",
       "0                               gini                               None  ...   \n",
       "1                            entropy                               None  ...   \n",
       "2                               gini                               None  ...   \n",
       "3                               gini                               None  ...   \n",
       "4                                NaN                                NaN  ...   \n",
       "\n",
       "   classifier:sgd:average classifier:sgd:fit_intercept  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2                     NaN                          NaN   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "\n",
       "   classifier:sgd:learning_rate  classifier:sgd:loss  classifier:sgd:penalty  \\\n",
       "0                           NaN                  NaN                     NaN   \n",
       "1                           NaN                  NaN                     NaN   \n",
       "2                           NaN                  NaN                     NaN   \n",
       "3                           NaN                  NaN                     NaN   \n",
       "4                           NaN                  NaN                     NaN   \n",
       "\n",
       "   classifier:sgd:tol  classifier:sgd:epsilon  classifier:sgd:l1_ratio  \\\n",
       "0                 NaN                     NaN                      NaN   \n",
       "1                 NaN                     NaN                      NaN   \n",
       "2                 NaN                     NaN                      NaN   \n",
       "3                 NaN                     NaN                      NaN   \n",
       "4                 NaN                     NaN                      NaN   \n",
       "\n",
       "  classifier:sgd:eta0 classifier:sgd:power_t  \n",
       "0                 NaN                    NaN  \n",
       "1                 NaN                    NaN  \n",
       "2                 NaN                    NaN  \n",
       "3                 NaN                    NaN  \n",
       "4                 NaN                    NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>balancing:strategy</th>\n",
       "      <th>classifier:__choice__</th>\n",
       "      <th>data_preprocessing:categorical_transformer:categorical_encoding:__choice__</th>\n",
       "      <th>data_preprocessing:categorical_transformer:category_coalescence:__choice__</th>\n",
       "      <th>data_preprocessing:numerical_transformer:imputation:strategy</th>\n",
       "      <th>data_preprocessing:numerical_transformer:rescaling:__choice__</th>\n",
       "      <th>feature_preprocessor:__choice__</th>\n",
       "      <th>classifier:random_forest:bootstrap</th>\n",
       "      <th>classifier:random_forest:criterion</th>\n",
       "      <th>...</th>\n",
       "      <th>classifier:sgd:average</th>\n",
       "      <th>classifier:sgd:fit_intercept</th>\n",
       "      <th>classifier:sgd:learning_rate</th>\n",
       "      <th>classifier:sgd:loss</th>\n",
       "      <th>classifier:sgd:penalty</th>\n",
       "      <th>classifier:sgd:tol</th>\n",
       "      <th>classifier:sgd:epsilon</th>\n",
       "      <th>classifier:sgd:l1_ratio</th>\n",
       "      <th>classifier:sgd:eta0</th>\n",
       "      <th>classifier:sgd:power_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.776970</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>median</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>mean</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>none</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>weighting</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>mean</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>weighting</td>\n",
       "      <td>extra_trees</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>mean</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>none</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>none</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>weighting</td>\n",
       "      <td>sgd</td>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>minority_coalescer</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>optimal</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>weighting</td>\n",
       "      <td>libsvm_svc</td>\n",
       "      <td>no_encoding</td>\n",
       "      <td>no_coalescense</td>\n",
       "      <td>mean</td>\n",
       "      <td>normalize</td>\n",
       "      <td>no_preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score balancing:strategy classifier:__choice__  \\\n",
       "497         0.776970               none            libsvm_svc   \n",
       "453         0.776364               none            libsvm_svc   \n",
       "248         0.776364               none            libsvm_svc   \n",
       "375         0.776364               none            libsvm_svc   \n",
       "407         0.776364          weighting            libsvm_svc   \n",
       "..               ...                ...                   ...   \n",
       "490         0.000000          weighting           extra_trees   \n",
       "553         0.000000               none            libsvm_svc   \n",
       "554         0.000000               none            libsvm_svc   \n",
       "555         0.000000          weighting                   sgd   \n",
       "556         0.000000          weighting            libsvm_svc   \n",
       "\n",
       "    data_preprocessing:categorical_transformer:categorical_encoding:__choice__  \\\n",
       "497                                   one_hot_encoding                           \n",
       "453                                        no_encoding                           \n",
       "248                                        no_encoding                           \n",
       "375                                        no_encoding                           \n",
       "407                                        no_encoding                           \n",
       "..                                                 ...                           \n",
       "490                                   one_hot_encoding                           \n",
       "553                                        no_encoding                           \n",
       "554                                   one_hot_encoding                           \n",
       "555                                   one_hot_encoding                           \n",
       "556                                        no_encoding                           \n",
       "\n",
       "    data_preprocessing:categorical_transformer:category_coalescence:__choice__  \\\n",
       "497                                 minority_coalescer                           \n",
       "453                                 minority_coalescer                           \n",
       "248                                     no_coalescense                           \n",
       "375                                     no_coalescense                           \n",
       "407                                 minority_coalescer                           \n",
       "..                                                 ...                           \n",
       "490                                 minority_coalescer                           \n",
       "553                                     no_coalescense                           \n",
       "554                                 minority_coalescer                           \n",
       "555                                 minority_coalescer                           \n",
       "556                                     no_coalescense                           \n",
       "\n",
       "    data_preprocessing:numerical_transformer:imputation:strategy  \\\n",
       "497                                             median             \n",
       "453                                               mean             \n",
       "248                                      most_frequent             \n",
       "375                                      most_frequent             \n",
       "407                                               mean             \n",
       "..                                                 ...             \n",
       "490                                               mean             \n",
       "553                                      most_frequent             \n",
       "554                                      most_frequent             \n",
       "555                                      most_frequent             \n",
       "556                                               mean             \n",
       "\n",
       "    data_preprocessing:numerical_transformer:rescaling:__choice__  \\\n",
       "497                                      robust_scaler              \n",
       "453                                      robust_scaler              \n",
       "248                                               none              \n",
       "375                                      robust_scaler              \n",
       "407                                      robust_scaler              \n",
       "..                                                 ...              \n",
       "490                               quantile_transformer              \n",
       "553                                               none              \n",
       "554                                      robust_scaler              \n",
       "555                                      robust_scaler              \n",
       "556                                          normalize              \n",
       "\n",
       "    feature_preprocessor:__choice__ classifier:random_forest:bootstrap  \\\n",
       "497                no_preprocessing                                NaN   \n",
       "453                no_preprocessing                                NaN   \n",
       "248                no_preprocessing                                NaN   \n",
       "375                no_preprocessing                                NaN   \n",
       "407                no_preprocessing                                NaN   \n",
       "..                              ...                                ...   \n",
       "490                no_preprocessing                                NaN   \n",
       "553                no_preprocessing                                NaN   \n",
       "554                no_preprocessing                                NaN   \n",
       "555                no_preprocessing                                NaN   \n",
       "556                no_preprocessing                                NaN   \n",
       "\n",
       "    classifier:random_forest:criterion  ... classifier:sgd:average  \\\n",
       "497                                NaN  ...                    NaN   \n",
       "453                                NaN  ...                    NaN   \n",
       "248                                NaN  ...                    NaN   \n",
       "375                                NaN  ...                    NaN   \n",
       "407                                NaN  ...                    NaN   \n",
       "..                                 ...  ...                    ...   \n",
       "490                                NaN  ...                    NaN   \n",
       "553                                NaN  ...                    NaN   \n",
       "554                                NaN  ...                    NaN   \n",
       "555                                NaN  ...                  False   \n",
       "556                                NaN  ...                    NaN   \n",
       "\n",
       "     classifier:sgd:fit_intercept classifier:sgd:learning_rate  \\\n",
       "497                           NaN                          NaN   \n",
       "453                           NaN                          NaN   \n",
       "248                           NaN                          NaN   \n",
       "375                           NaN                          NaN   \n",
       "407                           NaN                          NaN   \n",
       "..                            ...                          ...   \n",
       "490                           NaN                          NaN   \n",
       "553                           NaN                          NaN   \n",
       "554                           NaN                          NaN   \n",
       "555                          True                      optimal   \n",
       "556                           NaN                          NaN   \n",
       "\n",
       "     classifier:sgd:loss  classifier:sgd:penalty  classifier:sgd:tol  \\\n",
       "497                  NaN                     NaN                 NaN   \n",
       "453                  NaN                     NaN                 NaN   \n",
       "248                  NaN                     NaN                 NaN   \n",
       "375                  NaN                     NaN                 NaN   \n",
       "407                  NaN                     NaN                 NaN   \n",
       "..                   ...                     ...                 ...   \n",
       "490                  NaN                     NaN                 NaN   \n",
       "553                  NaN                     NaN                 NaN   \n",
       "554                  NaN                     NaN                 NaN   \n",
       "555        squared_hinge              elasticnet            0.000098   \n",
       "556                  NaN                     NaN                 NaN   \n",
       "\n",
       "     classifier:sgd:epsilon  classifier:sgd:l1_ratio  classifier:sgd:eta0  \\\n",
       "497                     NaN                      NaN                  NaN   \n",
       "453                     NaN                      NaN                  NaN   \n",
       "248                     NaN                      NaN                  NaN   \n",
       "375                     NaN                      NaN                  NaN   \n",
       "407                     NaN                      NaN                  NaN   \n",
       "..                      ...                      ...                  ...   \n",
       "490                     NaN                      NaN                  NaN   \n",
       "553                     NaN                      NaN                  NaN   \n",
       "554                     NaN                      NaN                  NaN   \n",
       "555                     NaN                 0.000965                  NaN   \n",
       "556                     NaN                      NaN                  NaN   \n",
       "\n",
       "    classifier:sgd:power_t  \n",
       "497                    NaN  \n",
       "453                    NaN  \n",
       "248                    NaN  \n",
       "375                    NaN  \n",
       "407                    NaN  \n",
       "..                     ...  \n",
       "490                    NaN  \n",
       "553                    NaN  \n",
       "554                    NaN  \n",
       "555                    NaN  \n",
       "556                    NaN  \n",
       "\n",
       "[557 rows x 80 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.concat([cv_res['mean_test_score'], res_norm], axis=1)\n",
    "res.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
