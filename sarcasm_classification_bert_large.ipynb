{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sarcasm_classification_xlnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcmFInhvWIRb",
        "outputId": "6ba770f7-bc60-423d-a265-0d7080909432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02obMEcVX9ab"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "with open('/content/drive/My Drive/data/train.jsonl') as f:\n",
        "    train_data = pd.read_json(f, lines=True)\n",
        "with open('/content/drive/My Drive/data/validation.jsonl') as f:\n",
        "    test_data = pd.read_json(f, lines=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q8nwf_IA6Iy"
      },
      "source": [
        "train_data.response = train_data.response.str.replace('@USER', '', regex=False)\n",
        "train_data.response = train_data.response.str.replace('<URL>', '', regex=False)\n",
        "\n",
        "test_data.response = test_data.response.str.replace('@USER', '', regex=False)\n",
        "test_data.response = test_data.response.str.replace('<URL>', '', regex=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuUzEiiNBsD1"
      },
      "source": [
        "train_data.context = train_data.context.apply(lambda x: [str.replace(s, '@USER', '') for s in x])\n",
        "train_data.context = train_data.context.apply(lambda x: [str.replace(s, '<URL>', '') for s in x])\n",
        "\n",
        "test_data.context = test_data.context.apply(lambda x: [str.replace(s, '@USER', '') for s in x])\n",
        "test_data.context = test_data.context.apply(lambda x: [str.replace(s, '<URL>', '') for s in x])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3iq_h-7NAN4",
        "outputId": "964ed091-b10d-4b5f-d525-aa9159adc00f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ekphrasis"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ekphrasis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/37c59d65e78c3a2aaf662df58faca7250eb6b36c559b912a39a7ca204cfb/ekphrasis-0.5.1.tar.gz (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 25.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 40kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 51kB 21.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 61kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 71kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (4.41.1)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting ujson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/84/e039c6ffc6603f2dfe966972d345d4f650a4ffd74b18c852ece645de12ac/ujson-4.0.1-cp36-cp36m-manylinux1_x86_64.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (3.2.5)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->ekphrasis) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Building wheels for collected packages: ekphrasis, ftfy\n",
            "  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-cp36-none-any.whl size=82844 sha256=c05e435a16ecce4296580b4b4b80bd69f2ae86e364f0cd35e5b947a5e94f6442\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c5/9b/c9b60f535a2cf9fdbc92d84c4801a010c35a9cd348011ed2a1\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=fcc29aeeb69ef2bdc589f20fdf2f20dbbdaea6c48c71fd8dbc4dbca42d01b000\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "Successfully built ekphrasis ftfy\n",
            "Installing collected packages: colorama, ujson, ftfy, ekphrasis\n",
            "Successfully installed colorama-0.4.4 ekphrasis-0.5.1 ftfy-5.8 ujson-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujRG-0fWNIeS",
        "outputId": "0c9dd9a6-2008-44c8-9922-038c3181680a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons\n",
        "\n",
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=False,  # fix HTML tokens\n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for word segmentation \n",
        "    segmenter=\"twitter\", \n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for spell correction\n",
        "    corrector=\"twitter\", \n",
        "    \n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=False,  # spell correction for elongated words\n",
        "    \n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=False).tokenize,\n",
        "    \n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading twitter - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
            "Reading twitter - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n",
            "Reading twitter - 1grams ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XScwPsxnNRq-"
      },
      "source": [
        "train_data.response = train_data.response.apply(text_processor.pre_process_doc)\n",
        "train_data.context = train_data.context.apply(lambda x: [text_processor.pre_process_doc(s) for s in x])\n",
        "\n",
        "test_data.response = test_data.response.apply(text_processor.pre_process_doc)\n",
        "test_data.context = test_data.context.apply(lambda x: [text_processor.pre_process_doc(s) for s in x])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_pGsLNh02H"
      },
      "source": [
        "def rev_and_join(x):\n",
        "  #x.reverse() \n",
        "  #return ' '.join(x)\n",
        "  return x.pop()\n",
        "\n",
        "train_data.context = train_data.context.apply(rev_and_join)\n",
        "test_data.context = test_data.context.apply(rev_and_join)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cTj-tUJkWao",
        "outputId": "5d7654f2-19dd-4c79-ea96-559102908777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.context"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [If, your, child, is, not, named, Barron, ., <...\n",
              "1       [having, to, make, up, excuses, of, why, your,...\n",
              "2       [I, ’, ll, remember, to, not, support, you, at...\n",
              "3       [But, not, half, as, stupid, as, Schiff, looks...\n",
              "4       [They, already, did, ., Obama, said, many, tim...\n",
              "                              ...                        \n",
              "4995    [We, will, work, on, this, and, reach, out, at...\n",
              "4996    [Yup, she, went, there, ., Nah, not, at, all, ...\n",
              "4997    [\", some, look, at, silence, as, boredom, or, ...\n",
              "4998    [Lots, of, people, believed, —, and, still, fe...\n",
              "4999    [Atiku, ', s, campaign, is, coming, wit, Arabi...\n",
              "Name: context, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBF871qRBZKt"
      },
      "source": [
        "#from itertools import chain\n",
        "#aug_neg_examples = list(chain.from_iterable(train_data['context']))\n",
        "#aug_data = pd.DataFrame(\n",
        "#    {'response': aug_neg_examples, \n",
        "#     'context': np.empty(len(aug_neg_examples)),\n",
        "#     'label': np.repeat('NOT_SARCASM', len(aug_neg_examples))\n",
        "#     })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbRx5-5WZsh"
      },
      "source": [
        "#train_data = train_data.append(aug_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7qKPjwNgjPP",
        "outputId": "6fe1030d-3f32-429c-be8d-57f4bb9d1aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 17 18:45:54 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UklMTAdvguH-"
      },
      "source": [
        "!pip install tensorflow-gpu >> /dev/null\n",
        "!pip install --upgrade grpcio >> /dev/null\n",
        "!pip install tqdm  >> /dev/null\n",
        "!pip install bert-for-tf2 >> /dev/null"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROPEIZMaZsLA"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvDzlUHkiDBf"
      },
      "source": [
        "%matplotlib inline\n",
        "RANDOM_SEED = 9\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjSmmAvoa5YE",
        "outputId": "27dfa953-5b36-4f47-bee1-012b442ab140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 18:46:43--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.176, 172.217.2.112, 172.217.164.144, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   190MB/s    in 2.0s    \n",
            "\n",
            "2020-11-17 18:46:45 (190 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlufbnkXiOif"
      },
      "source": [
        "os.makedirs(\"model\", exist_ok=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA0pYBCFiQzy"
      },
      "source": [
        "!mv uncased_L-12_H-768_A-12/ model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXvtmPk3iUpe"
      },
      "source": [
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "\n",
        "bert_ckpt_dir = os.path.join(\"model/\", bert_model_name)\n",
        "bert_ckpt_file = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaIz-NE5cVn6"
      },
      "source": [
        "class SarcasmDetectionData:\n",
        "\n",
        "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=72):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_seq_len = 0\n",
        "    self.classes = classes\n",
        "    \n",
        "    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
        "\n",
        "    print(\"max seq_len\", self.max_seq_len)\n",
        "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
        "\n",
        "  def _prepare(self, df):\n",
        "    x, y = [], []\n",
        "    \n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "      text, context, label = ' '.join(row['response']),' '.join(row['context']), row['label']\n",
        "      tokens = [\"[CLS]\"]\n",
        "      tokens.extend(self.tokenizer.tokenize(text))\n",
        "      tokens.append(\"[PAD]\")\n",
        "      tokens.extend(self.tokenizer.tokenize(context))\n",
        "      tokens.append(\"[SEP]\")\n",
        "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "      x.append(token_ids)\n",
        "      y.append(self.classes.index(label))\n",
        "\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "  def _pad(self, ids):\n",
        "    x = []\n",
        "    for input_ids in ids:\n",
        "      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "      x.append(np.array(input_ids))\n",
        "    return np.array(x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRGDioBi8rJ"
      },
      "source": [
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeZ0mkshgr8u"
      },
      "source": [
        "def create_model(max_seq_len, bert_ckpt_file):\n",
        "\n",
        "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "      bc = StockBertConfig.from_json_string(reader.read())\n",
        "      bert_params = map_stock_config_to_params(bc)\n",
        "      bert_params.adapter_size = None\n",
        "      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "        \n",
        "  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
        "  bert_output = bert(input_ids)\n",
        "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
        "  cls_out = keras.layers.Dropout(0.3)(cls_out)\n",
        "  logits = keras.layers.Dense(units=512, activation=\"tanh\")(cls_out)\n",
        "  logits = keras.layers.Dropout(0.3)(logits)\n",
        "  logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "\n",
        "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "  load_stock_weights(bert, bert_ckpt_file)\n",
        "        \n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJi79BejJp1"
      },
      "source": [
        "classes = train_data.label.unique().tolist()\n",
        "\n",
        "data = SarcasmDetectionData(train_data, test_data, tokenizer, classes, max_seq_len=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxX-4IpDjt3Z",
        "outputId": "b8ed48ec-c034-42e4-ba14-dd6d57b432b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model(data.max_seq_len, bert_ckpt_file)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading 196 BERT weights from: model/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7f7bee1ab0b8> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from checkpoint: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n",
            "\tcls/seq_relationship/output_bias\n",
            "\tcls/seq_relationship/output_weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwLxyGriCDT",
        "outputId": "d0cede50-8999-47f5-bff8-9fe48c41309a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "bert (BertModelLayer)        (None, 256, 768)          108890112 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               393728    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 109,284,866\n",
            "Trainable params: 109,284,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBtKtminj1CY"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(1e-5),\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvomsGolsvKx"
      },
      "source": [
        "modelCheckpoint = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/best_sarcasm_model14.hdf5', save_best_only = True)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjCCE0apj5DG",
        "outputId": "cb8c90b8-2225-4cf9-9935-d83f82f7da25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(\n",
        "  x=data.train_x, \n",
        "  y=data.train_y,\n",
        "  validation_data=(data.test_x, data.test_y),\n",
        "  batch_size=24,\n",
        "  shuffle=True,\n",
        "  epochs=15,\n",
        "  callbacks=[modelCheckpoint]\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "209/209 [==============================] - ETA: 0s - loss: 0.5966 - acc: 0.6930WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_test_batch_end` time: 0.4280s). Check your callbacks.\n",
            "209/209 [==============================] - 364s 2s/step - loss: 0.5966 - acc: 0.6930 - val_loss: 0.5996 - val_acc: 0.7000\n",
            "Epoch 2/15\n",
            "209/209 [==============================] - 364s 2s/step - loss: 0.5303 - acc: 0.7722 - val_loss: 0.5821 - val_acc: 0.7122\n",
            "Epoch 3/15\n",
            "209/209 [==============================] - 357s 2s/step - loss: 0.4887 - acc: 0.8200 - val_loss: 0.5860 - val_acc: 0.7100\n",
            "Epoch 4/15\n",
            "209/209 [==============================] - 362s 2s/step - loss: 0.4649 - acc: 0.8442 - val_loss: 0.5795 - val_acc: 0.7289\n",
            "Epoch 5/15\n",
            "209/209 [==============================] - 357s 2s/step - loss: 0.4363 - acc: 0.8738 - val_loss: 0.5801 - val_acc: 0.7211\n",
            "Epoch 6/15\n",
            "209/209 [==============================] - 356s 2s/step - loss: 0.4196 - acc: 0.8910 - val_loss: 0.5982 - val_acc: 0.6989\n",
            "Epoch 7/15\n",
            "209/209 [==============================] - 357s 2s/step - loss: 0.4081 - acc: 0.9038 - val_loss: 0.5922 - val_acc: 0.7133\n",
            "Epoch 8/15\n",
            "209/209 [==============================] - 356s 2s/step - loss: 0.4007 - acc: 0.9106 - val_loss: 0.6132 - val_acc: 0.6928\n",
            "Epoch 9/15\n",
            "209/209 [==============================] - 356s 2s/step - loss: 0.3901 - acc: 0.9226 - val_loss: 0.5960 - val_acc: 0.7056\n",
            "Epoch 10/15\n",
            "209/209 [==============================] - 356s 2s/step - loss: 0.3823 - acc: 0.9304 - val_loss: 0.5852 - val_acc: 0.7211\n",
            "Epoch 11/15\n",
            "209/209 [==============================] - 356s 2s/step - loss: 0.3843 - acc: 0.9290 - val_loss: 0.5885 - val_acc: 0.7200\n",
            "Epoch 12/15\n",
            "209/209 [==============================] - 356s 2s/step - loss: 0.3747 - acc: 0.9386 - val_loss: 0.5934 - val_acc: 0.7106\n",
            "Epoch 13/15\n",
            "209/209 [==============================] - 357s 2s/step - loss: 0.3735 - acc: 0.9390 - val_loss: 0.5881 - val_acc: 0.7178\n",
            "Epoch 14/15\n",
            "209/209 [==============================] - 363s 2s/step - loss: 0.3729 - acc: 0.9404 - val_loss: 0.5758 - val_acc: 0.7350\n",
            "Epoch 15/15\n",
            "209/209 [==============================] - 357s 2s/step - loss: 0.3717 - acc: 0.9404 - val_loss: 0.5760 - val_acc: 0.7278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT1ZxnJpbt62"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/best_sarcasm_model8.hdf5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJksOgpXkLxH"
      },
      "source": [
        "y_pred = model.predict(data.test_x).argmax(axis=-1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2qLDmE1kNn8"
      },
      "source": [
        "print(classification_report(data.test_y, y_pred, target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY7cI-pZdCn8"
      },
      "source": [
        "rows = [['twitter_' + str(i+1), 'SARCASM' if r == 0 else 'NOT_SARCASM'] for i, r in enumerate(y_pred)]\n",
        "results = pd.DataFrame(rows, columns=[\"ID\", \"RESULT\"])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53WvcGNcd3D8",
        "outputId": "9bf1f74f-f4e0-48ec-9533-31fe4423e563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "results.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>RESULT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>NOT_SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>NOT_SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID       RESULT\n",
              "0  twitter_1  NOT_SARCASM\n",
              "1  twitter_2      SARCASM\n",
              "2  twitter_3      SARCASM\n",
              "3  twitter_4  NOT_SARCASM\n",
              "4  twitter_5      SARCASM"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8s4hrwlAGnV"
      },
      "source": [
        "results.to_csv('/content/drive/My Drive/answer.txt', header = False, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}